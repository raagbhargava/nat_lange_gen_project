{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a13649e4-277b-47dc-95d9-23e73cc783fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2023.9.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /opt/conda/lib/python3.10/site-packages (from torch) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.10/site-packages (from torch) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.52)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74000a79-de9d-4d9c-b239-da2f537e464d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.1.99)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cbdbbb7-d27b-463d-abb7-ee52968b599e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.35.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.9.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a94c4a8f-a791-4b53-afa3-1c450bd6ca43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import os\n",
    "\n",
    "# Importing the T5 modules from huggingface/transformers\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "# rich: for a better display on terminal\n",
    "from rich.table import Column, Table\n",
    "from rich import box\n",
    "from rich.console import Console\n",
    "\n",
    "# define a rich console logger\n",
    "console = Console(record=True)\n",
    "\n",
    "# to display dataframe in ASCII format\n",
    "def display_df(df):\n",
    "    \"\"\"display dataframe in ASCII format\"\"\"\n",
    "\n",
    "    console = Console()\n",
    "    table = Table(\n",
    "        Column(\"source_text\", justify=\"center\"),\n",
    "        Column(\"target_text\", justify=\"center\"),\n",
    "        title=\"Sample Data\",\n",
    "        pad_edge=False,\n",
    "        box=box.ASCII,\n",
    "    )\n",
    "\n",
    "    for i, row in enumerate(df.values.tolist()):\n",
    "        table.add_row(row[0], row[1])\n",
    "\n",
    "    console.print(table)\n",
    "\n",
    "# training logger to log training progress\n",
    "training_logger = Table(\n",
    "    Column(\"Epoch\", justify=\"center\"),\n",
    "    Column(\"Steps\", justify=\"center\"),\n",
    "    Column(\"Loss\", justify=\"center\"),\n",
    "    title=\"Training Status\",\n",
    "    pad_edge=False,\n",
    "    box=box.ASCII,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9a97865-015d-4e3e-9a6c-9f057ca272ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Dec 13 17:12:34 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            On   | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   50C    P8     9W /  70W |      2MiB / 15360MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eec0f3b4-13a2-4bbd-a160-eb3208de3c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Dec 13 17:12:34 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            On   | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   50C    P8    10W /  70W |      2MiB / 15360MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "get_ipython().system('nvidia-smi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa1adea8-7f67-4ceb-a8b6-f50841d2cc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Setting up the device for GPU usage\n",
    "from torch import cuda\n",
    "device = 'cuda:0' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "426823f7-b831-4c6d-b8a2-52d9a9871841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48cd2fb6-fd0c-4b88-9f29-a546364cfe61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YourDataSetClass(Dataset):\n",
    "    \"\"\"\n",
    "    Creating a custom dataset for reading the dataset and\n",
    "    loading it into the dataloader to pass it to the\n",
    "    neural network for finetuning the model\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, dataframe, tokenizer, source_len, target_len, source_text, target_text\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initializes a Dataset class\n",
    "\n",
    "        Args:\n",
    "            dataframe (pandas.DataFrame): Input dataframe\n",
    "            tokenizer (transformers.tokenizer): Transformers tokenizer\n",
    "            source_len (int): Max length of source text\n",
    "            target_len (int): Max length of target text\n",
    "            source_text (str): column name of source text\n",
    "            target_text (str): column name of target text\n",
    "        \"\"\"\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.source_len = source_len\n",
    "        self.summ_len = target_len\n",
    "        self.target_text = self.data[target_text]\n",
    "        self.source_text = self.data[source_text]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"returns the length of dataframe\"\"\"\n",
    "\n",
    "        return len(self.target_text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"return the input ids, attention masks and target ids\"\"\"\n",
    "\n",
    "        source_text = str(self.source_text[index])\n",
    "        target_text = str(self.target_text[index])\n",
    "\n",
    "        # cleaning data so as to ensure data is in string type\n",
    "        source_text = \" \".join(source_text.split())\n",
    "        target_text = \" \".join(target_text.split())\n",
    "\n",
    "        source = self.tokenizer.batch_encode_plus(\n",
    "            [source_text],\n",
    "            max_length=self.source_len,\n",
    "            pad_to_max_length=True,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        target = self.tokenizer.batch_encode_plus(\n",
    "            [target_text],\n",
    "            max_length=self.summ_len,\n",
    "            pad_to_max_length=True,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        source_ids = source[\"input_ids\"].squeeze()\n",
    "        source_mask = source[\"attention_mask\"].squeeze()\n",
    "        target_ids = target[\"input_ids\"].squeeze()\n",
    "        target_mask = target[\"attention_mask\"].squeeze()\n",
    "\n",
    "        return {\n",
    "            \"source_ids\": source_ids.to(dtype=torch.long),\n",
    "            \"source_mask\": source_mask.to(dtype=torch.long),\n",
    "            \"target_ids\": target_ids.to(dtype=torch.long),\n",
    "            \"target_ids_y\": target_ids.to(dtype=torch.long),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66045d90-ed06-499b-9e7c-2a3d888955dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, tokenizer, model, device, loader, optimizer):\n",
    "\n",
    "    \"\"\"\n",
    "    Function to be called for training with the parameters passed from main function\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    model.train()\n",
    "    for _, data in enumerate(loader, 0):\n",
    "        y = data[\"target_ids\"].to(device, dtype=torch.long)\n",
    "        y_ids = y[:, :-1].contiguous()\n",
    "        lm_labels = y[:, 1:].clone().detach()\n",
    "        lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n",
    "        ids = data[\"source_ids\"].to(device, dtype=torch.long)\n",
    "        mask = data[\"source_mask\"].to(device, dtype=torch.long)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=ids,\n",
    "            attention_mask=mask,\n",
    "            decoder_input_ids=y_ids,\n",
    "            labels=lm_labels,\n",
    "        )\n",
    "        loss = outputs[0]\n",
    "\n",
    "        if _ % 500 == 0:\n",
    "            training_logger.add_row(str(epoch), str(_), str(loss))\n",
    "            console.print(training_logger)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea1bb3e6-a4d2-42b4-81d5-f11085109ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(epoch, tokenizer, model, device, loader):\n",
    "    model.eval()\n",
    "    inputs = []\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(loader, 0):\n",
    "            y = data['target_ids'].to(device, dtype = torch.long)\n",
    "            y_ids = y[:, :-1].contiguous()\n",
    "            lm_labels = y[:, 1:].clone().detach()\n",
    "            lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n",
    "            ids = data['source_ids'].to(device, dtype = torch.long)\n",
    "            mask = data['source_mask'].to(device, dtype = torch.long)\n",
    "            \n",
    "\n",
    "            generated_ids = model.generate(\n",
    "              input_ids = ids,\n",
    "              attention_mask = mask, \n",
    "              max_length=512, \n",
    "                min_length = 250,\n",
    "              num_beams = 5,\n",
    "              no_repeat_ngram_size = 5,\n",
    "              #topp = 0.9,\n",
    "              #do_sample=True,\n",
    "              repetition_penalty=5.8, \n",
    "              length_penalty=1, \n",
    "              early_stopping=True\n",
    "              )\n",
    "            preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
    "            target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)for t in y]\n",
    "            input_text = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)for t in ids]\n",
    "            if _%50==0:\n",
    "                outputs = model(\n",
    "                        input_ids=ids,\n",
    "                        attention_mask=mask,\n",
    "                        decoder_input_ids=y_ids,\n",
    "                        labels=lm_labels,\n",
    "                        )\n",
    "                loss = outputs[0]\n",
    "                console.print(f'Completed {_}')\n",
    "                console.print('loss: '+ str(loss))\n",
    "            \n",
    "            predictions.extend(preds)\n",
    "            actuals.extend(target)\n",
    "            inputs.extend(input_text)\n",
    "    return inputs, predictions, actuals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c4cf0c8-cd91-45b1-924d-1ad4ca7ceb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(tokenizer, model, device, loader):\n",
    "    model.eval()\n",
    "    inputs = []\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(loader, 0):\n",
    "            y = data['target_ids'].to(device, dtype = torch.long)\n",
    "            y_ids = y[:, :-1].contiguous()\n",
    "            lm_labels = y[:, 1:].clone().detach()\n",
    "            lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n",
    "            ids = data['source_ids'].to(device, dtype = torch.long)\n",
    "            mask = data['source_mask'].to(device, dtype = torch.long)\n",
    "            \n",
    "\n",
    "            generated_ids = model.generate(\n",
    "              input_ids = ids,\n",
    "              attention_mask = mask, \n",
    "              max_length=512, \n",
    "                min_length = 100,\n",
    "              num_beams = 4,\n",
    "              no_repeat_ngram_size = 5,\n",
    "              #topp = 0.9,\n",
    "              #do_sample=True,\n",
    "              repetition_penalty=5.8, \n",
    "              length_penalty=1, \n",
    "              early_stopping=True\n",
    "              )\n",
    "            preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
    "            input_text = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)for t in ids]\n",
    "            if _%50==0:\n",
    "                console.print(f'Completed {_}')\n",
    "\n",
    "            predictions.extend(preds)\n",
    "            inputs.extend(input_text)\n",
    "    return inputs, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a29cd14-9c80-4ace-88e9-3ab01ef8c269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BartTrainer(\n",
    "    dataframe, source_text, target_text, model_params, model, tokenizer, output_dir=\"./outputs/\"\n",
    "):\n",
    "\n",
    "    \"\"\"\n",
    "    T5 trainer\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Set random seeds and deterministic pytorch for reproducibility\n",
    "    torch.manual_seed(model_params[\"SEED\"])  # pytorch random seed\n",
    "    np.random.seed(model_params[\"SEED\"])  # numpy random seed\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    # logging\n",
    "    console.log(f\"\"\"[Model]: Loading {model_params[\"MODEL\"]}...\\n\"\"\")\n",
    "\n",
    "    \n",
    "\n",
    "    # logging\n",
    "    console.log(f\"[Data]: Reading data...\\n\")\n",
    "\n",
    "    # Importing the raw dataset\n",
    "    dataframe = dataframe[[source_text, target_text]]\n",
    "    display_df(dataframe.head(2))\n",
    "\n",
    "    # Creation of Dataset and Dataloader\n",
    "    # Defining the train size. So x% of the data will be used for training and the rest for validation.\n",
    "    train_size = 0.998\n",
    "    train_dataset = dataframe.sample(frac=train_size, random_state=model_params[\"SEED\"])\n",
    "    val_dataset = dataframe.drop(train_dataset.index).reset_index(drop=True)\n",
    "    train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "    console.print(f\"FULL Dataset: {dataframe.shape}\")\n",
    "    console.print(f\"TRAIN Dataset: {train_dataset.shape}\")\n",
    "    console.print(f\"TEST Dataset: {val_dataset.shape}\\n\")\n",
    "\n",
    "    # Creating the Training and Validation dataset for further creation of Dataloader\n",
    "    training_set = YourDataSetClass(\n",
    "        train_dataset,\n",
    "        tokenizer,\n",
    "        model_params[\"MAX_SOURCE_TEXT_LENGTH\"],\n",
    "        model_params[\"MAX_TARGET_TEXT_LENGTH\"],\n",
    "        source_text,\n",
    "        target_text,\n",
    "    )\n",
    "    val_set = YourDataSetClass(\n",
    "        val_dataset,\n",
    "        tokenizer,\n",
    "        model_params[\"MAX_SOURCE_TEXT_LENGTH\"],\n",
    "        model_params[\"MAX_TARGET_TEXT_LENGTH\"],\n",
    "        source_text,\n",
    "        target_text,\n",
    "    )\n",
    "\n",
    "    # Defining the parameters for creation of dataloaders\n",
    "    train_params = {\n",
    "        \"batch_size\": model_params[\"TRAIN_BATCH_SIZE\"],\n",
    "        \"shuffle\": True,\n",
    "        \"num_workers\": 0,\n",
    "    }\n",
    "\n",
    "    val_params = {\n",
    "        \"batch_size\": model_params[\"VALID_BATCH_SIZE\"],\n",
    "        \"shuffle\": False,\n",
    "        \"num_workers\": 0,\n",
    "    }\n",
    "\n",
    "    # Creation of Dataloaders for testing and validation. This will be used down for training and validation stage for the model.\n",
    "    training_loader = DataLoader(training_set, **train_params)\n",
    "    val_loader = DataLoader(val_set, **val_params)\n",
    "\n",
    "    # Defining the optimizer that will be used to tune the weights of the network in the training session.\n",
    "    optimizer = torch.optim.Adam(\n",
    "        params=model.parameters(), lr=model_params[\"LEARNING_RATE\"]\n",
    "    )\n",
    "\n",
    "    # Training loop\n",
    "    console.log(f\"[Initiating Fine Tuning]...\\n\")\n",
    "\n",
    "    for epoch in range(model_params[\"TRAIN_EPOCHS\"]):\n",
    "        train(epoch, tokenizer, model, device, training_loader, optimizer)\n",
    "        console.log(f\"[Initiating Validation]...\\n\")\n",
    "        inputs, predictions, actuals = validate(epoch, tokenizer, model, device, val_loader)\n",
    "        final_df = pd.DataFrame({'Input': inputs, \"Generated Text\": predictions, \"Actual Text\": actuals})\n",
    "        final_df.to_csv(os.path.join(output_dir, \"predictions\"+str(epoch)+\".csv\"))\n",
    "\n",
    "    console.log(f\"[Saving Model]...\\n\")\n",
    "    # Saving the model after training\n",
    "    path = os.path.join(output_dir, \"model_files\")\n",
    "    model.save_pretrained(path)\n",
    "    tokenizer.save_pretrained(path)\n",
    "\n",
    "    # evaluating test dataset\n",
    "    \n",
    "\n",
    "    console.save_text(os.path.join(output_dir, \"logs.txt\"))\n",
    "\n",
    "    console.log(f\"[Validation Completed.]\\n\")\n",
    "    console.print(\n",
    "        f\"\"\"[Model] Model saved @ {os.path.join(output_dir, \"model_files\")}\\n\"\"\"\n",
    "    )\n",
    "    console.print(\n",
    "        f\"\"\"[Validation] Generation on Validation data saved @ {os.path.join(output_dir,'predictions.csv')}\\n\"\"\"\n",
    "    )\n",
    "    console.print(f\"\"\"[Logs] Logs saved @ {os.path.join(output_dir,'logs.txt')}\\n\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b9b1b4f-b11f-4869-b8ec-36844d51af51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# files=['news_yake_keywords.json','roc_yake_keywords.json', 'poetry_yake_keyword.json']\n",
    "\n",
    "# def merge_JsonFiles(filename):\n",
    "#     result = list()\n",
    "#     for f1 in filename:\n",
    "#         with open(f1, 'r') as infile:\n",
    "#             result.append(json.load(infile))\n",
    "\n",
    "#     with open('merged_yake_keywords.json', 'w') as output_file:\n",
    "#         json.dump(result, output_file)\n",
    "\n",
    "# merge_JsonFiles(files)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10898eb6-3a10-430f-8205-1cb4bd0407d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open('news_yake_keywords.json', errors='ignore').readlines()\n",
    "# news =  json.loads(f[0])\n",
    "# g = open('roc_yake_keywords.json', errors='ignore').readlines()\n",
    "# roc =  json.loads(g[0])\n",
    "# h = open('poetry_yake_keywords.json', errors='ignore').readlines()\n",
    "# poetry =  json.loads(g[0])\n",
    "# all_scary =  json.loads(f[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1301c48-eab8-427d-b750-60db2c8df0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(news), len(roc), len(poetry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49b66fc3-b931-4941-b864-0c153b232435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_poetry_foundation = roc + poetry + news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ca7b639-91db-4ae4-8b88-ffbf8a653c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('shakespeare.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da890edf-1c41-4e8d-a66c-995514076caa",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Replace with the desired number of columns\n",
    "df = df.iloc[:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "def98ef4-ff2f-40f8-9e00-4532d39f472b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "413541a8-8e95-43f0-a1fd-95c5c9a9e5e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>og</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>42928-1500614319216-63344</td>\n",
       "      <td>You do not meet a man but frowns:</td>\n",
       "      <td>Every man you meet these days is frowning.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>42928-1500614326583-89821</td>\n",
       "      <td>our bloods  No more obey the heavens than our...</td>\n",
       "      <td>Our bodies are in agreement with the planetar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A-63849</td>\n",
       "      <td>But what's the matter?</td>\n",
       "      <td>What's wrong?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>42930-1500614347266-80123</td>\n",
       "      <td>His daughter, and the heir of's kingdom, whom...</td>\n",
       "      <td>The king wanted his daughter, the only heir to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>42930-1500614355280-38326</td>\n",
       "      <td>she's wedded;  Her husband banish'd; she impr...</td>\n",
       "      <td>She's married, her husband is banished, she's...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                         id  \\\n",
       "0           0  42928-1500614319216-63344   \n",
       "1           1  42928-1500614326583-89821   \n",
       "2           2                    A-63849   \n",
       "3           3  42930-1500614347266-80123   \n",
       "4           4  42930-1500614355280-38326   \n",
       "\n",
       "                                                  og  \\\n",
       "0                 You do not meet a man but frowns:    \n",
       "1   our bloods  No more obey the heavens than our...   \n",
       "2                           But what's the matter?     \n",
       "3   His daughter, and the heir of's kingdom, whom...   \n",
       "4   she's wedded;  Her husband banish'd; she impr...   \n",
       "\n",
       "                                                   t  \n",
       "0         Every man you meet these days is frowning.  \n",
       "1   Our bodies are in agreement with the planetar...  \n",
       "2                                      What's wrong?  \n",
       "3  The king wanted his daughter, the only heir to...  \n",
       "4   She's married, her husband is banished, she's...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00805cc5-7047-4c64-b338-3eb30e682988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Every man you meet these days is frowning.</td>\n",
       "      <td>You do not meet a man but frowns:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Our bodies are in agreement with the planetar...</td>\n",
       "      <td>our bloods  No more obey the heavens than our...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What's wrong?</td>\n",
       "      <td>But what's the matter?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The king wanted his daughter, the only heir to...</td>\n",
       "      <td>His daughter, and the heir of's kingdom, whom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>She's married, her husband is banished, she's...</td>\n",
       "      <td>she's wedded;  Her husband banish'd; she impr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0         Every man you meet these days is frowning.   \n",
       "1   Our bodies are in agreement with the planetar...   \n",
       "2                                      What's wrong?   \n",
       "3  The king wanted his daughter, the only heir to...   \n",
       "4   She's married, her husband is banished, she's...   \n",
       "\n",
       "                                            keywords  \n",
       "0                 You do not meet a man but frowns:   \n",
       "1   our bloods  No more obey the heavens than our...  \n",
       "2                           But what's the matter?    \n",
       "3   His daughter, and the heir of's kingdom, whom...  \n",
       "4   she's wedded;  Her husband banish'd; she impr...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = df.rename(columns={'t': 'title'})\n",
    "df = df.rename(columns={'og': 'keywords'})\n",
    "\n",
    "#Create a new DataFrame with only two columns\n",
    "df = df[['title', 'keywords']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3889dddd-d310-42f8-8090-1327de00f7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def clean_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = ''.join([char for char in text if char not in string.punctuation])\n",
    "    \n",
    "    # Remove symbols and numbers\n",
    "    text = ''.join([char for char in text if char.isalpha() or char.isspace()])\n",
    "    \n",
    "    # Remove extra whitespaces\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "# Apply the clean_text function to the 'Text' column\n",
    "df['title'] = df['title'].apply(clean_text)\n",
    "# Apply the clean_text function to the 'Text' column\n",
    "df['keywords'] = df['keywords'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3de3134a-1ba7-4c89-8f21-6a9615407e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text to prepend\n",
    "text_to_prepend = 'Translate English to Shakespearean: '\n",
    "\n",
    "# Prepend text to the beginning of each row in the specified column\n",
    "df['title'] = text_to_prepend + df['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd9f46bc-31d9-4eaa-8454-a7a50079eab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Translate English to Shakespearean: every man ...</td>\n",
       "      <td>you do not meet a man but frowns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Translate English to Shakespearean: our bodies...</td>\n",
       "      <td>our bloods no more obey the heavens than our c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Translate English to Shakespearean: whats wrong</td>\n",
       "      <td>but whats the matter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Translate English to Shakespearean: the king w...</td>\n",
       "      <td>his daughter and the heir ofs kingdom whom he ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Translate English to Shakespearean: shes marri...</td>\n",
       "      <td>shes wedded her husband banishd she imprisond ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Translate English to Shakespearean: every man ...   \n",
       "1  Translate English to Shakespearean: our bodies...   \n",
       "2    Translate English to Shakespearean: whats wrong   \n",
       "3  Translate English to Shakespearean: the king w...   \n",
       "4  Translate English to Shakespearean: shes marri...   \n",
       "\n",
       "                                            keywords  \n",
       "0                   you do not meet a man but frowns  \n",
       "1  our bloods no more obey the heavens than our c...  \n",
       "2                               but whats the matter  \n",
       "3  his daughter and the heir ofs kingdom whom he ...  \n",
       "4  shes wedded her husband banishd she imprisond ...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95eb813e-a723-4d65-8a16-cff39e9d2dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# special_token = '.'\n",
    "# mask_token = '<MASK>'\n",
    "# eos_token = '</s>'\n",
    "\n",
    "# X_titles = []\n",
    "# y_keywords = []\n",
    "# template = [mask_token, mask_token, mask_token]\n",
    "# prompt = 'Generate keywords for the title: '\n",
    "# title_set = []\n",
    "\n",
    "# for poem in all_poetry_foundation:\n",
    "#     title_set.append(poem['Theme'])\n",
    "#     title = prompt + poem['Theme']\n",
    "#     paddings = []\n",
    "#     temp = []\n",
    "#     count = 0\n",
    "#     for key in poem['keywords']:\n",
    "#         if key == ['<paragraph>']:\n",
    "#             continue\n",
    "#         count += 1\n",
    "#         mask = template[:len(key)]\n",
    "#         paddings.append('Keywords '+ str(count) + ': '+ str(mask) )        \n",
    "#         temp.append('Keywords '+ str(count) + ': '+ str(key))\n",
    "\n",
    "#     paddings = (\" \"+special_token+\" \").join(paddings).replace('<paragraph> ','')\n",
    "#     temp = (\" \"+special_token+\" \").join(temp).replace('<paragraph> ','')\n",
    "\n",
    "#     X_titles.append(title + '. ' + paddings)\n",
    "#     #X_titles.append(title)\n",
    "#     y_keywords.append(temp) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c7359c0-132f-4b49-bce0-140511f386d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Translate English to Shakespearean: every man ...\n",
       "1    Translate English to Shakespearean: our bodies...\n",
       "2      Translate English to Shakespearean: whats wrong\n",
       "3    Translate English to Shakespearean: the king w...\n",
       "4    Translate English to Shakespearean: shes marri...\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = [X_titles, y_keywords]\n",
    "# df = pd.DataFrame(np.array(data).T, columns = ['title', 'keywords'])\n",
    "df['title'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "96c484f5-4740-480f-a062-627996228ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Translate English to Shakespearean: im a virgin sir and though ive never asked for anyones attention ive had a lot of people stare at me as though i were a shooting star'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title'][10005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "19d8152a-9bd4-425d-ba98-951661cd190c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i am a maid my lord that neer before invited eyes but have been gazed on like a comet'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['keywords'][10005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "47ae10ee-24f4-42c6-8e2a-f8833444346f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define model parameters specific to bart\n",
    "model_params = {\n",
    "    \"TASK\" : \"seq2seq\",\n",
    "    \"MODEL\": \"facebook/bart-large\",  \n",
    "    \"TRAIN_BATCH_SIZE\": 2,  # training batch size\n",
    "    \"VALID_BATCH_SIZE\": 2,  # validation batch size\n",
    "    \"TRAIN_EPOCHS\": 4,  # number of training epochs\n",
    "    \"VAL_EPOCHS\": 1,  # number of validation epochs\n",
    "    \"LEARNING_RATE\": 5e-6,  # learning rate\n",
    "    \"MAX_SOURCE_TEXT_LENGTH\": 512,  # max length of source text\n",
    "    \"MAX_TARGET_TEXT_LENGTH\": 512,  # max length of target text\n",
    "    \"SEED\": 42,  # set seed for reproducibility\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7df8b237-b384-43c9-8442-1f8a2211e760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenzier for encoding the text\n",
    "tokenizer = BartTokenizer.from_pretrained(model_params[\"MODEL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f3c8be53-7a92-4cf3-aca1-4ecf1f00eaca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s>'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "56ad093d-4918-4c22-8910-a4cc0f952ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further this model is sent to device (GPU/TPU) for using the hardware.\n",
    "model = BartForConditionalGeneration.from_pretrained(model_params[\"MODEL\"])\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c33d581-e27f-4e6a-9ca8-98900cdf98f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer(df['title'][15005])\n",
    "\n",
    "len(tokens['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3b3353a9-7c3c-404a-83a1-b4824de7e4f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what mean you caesar think you to walk forthyou shall not stir out of your house today'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['keywords'][15005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "71784367-40a6-43d0-a209-c4de2ed7f687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer(df['keywords'][15005])\n",
    "\n",
    "len(tokens['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fff406aa-1b4f-407e-868b-76afae4b5475",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir= model_params['MODEL']+\"_batch_size_\"+ str(model_params['TRAIN_BATCH_SIZE']) + \"_lr_\"+ str(model_params['LEARNING_RATE'])+ \"_\" + model_params['TASK']\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33f1c99-177e-4f3a-a11b-c1a14b7e8d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[17:12:44] </span><span style=\"font-weight: bold\">[</span>Model<span style=\"font-weight: bold\">]</span>: Loading facebook/bart-large<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                 <a href=\"file:///var/tmp/ipykernel_294843/2315885737.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2315885737.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///var/tmp/ipykernel_294843/2315885737.py#16\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">16</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[17:12:44]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mModel\u001b[1m]\u001b[0m: Loading facebook/bart-large\u001b[33m...\u001b[0m                                                 \u001b]8;id=261683;file:///var/tmp/ipykernel_294843/2315885737.py\u001b\\\u001b[2m2315885737.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=28417;file:///var/tmp/ipykernel_294843/2315885737.py#16\u001b\\\u001b[2m16\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m                                                                                        \u001b[2m                \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"font-weight: bold\">[</span>Data<span style=\"font-weight: bold\">]</span>: Reading data<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                                 <a href=\"file:///var/tmp/ipykernel_294843/2315885737.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2315885737.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///var/tmp/ipykernel_294843/2315885737.py#21\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">21</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mData\u001b[1m]\u001b[0m: Reading data\u001b[33m...\u001b[0m                                                                 \u001b]8;id=163173;file:///var/tmp/ipykernel_294843/2315885737.py\u001b\\\u001b[2m2315885737.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=578688;file:///var/tmp/ipykernel_294843/2315885737.py#21\u001b\\\u001b[2m21\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m                                                                                        \u001b[2m                \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                    Sample Data                                                    </span>\n",
       "+-----------------------------------------------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">                      source_text                       </span>|<span style=\"font-weight: bold\">                       target_text                      </span>|\n",
       "|--------------------------------------------------------+--------------------------------------------------------|\n",
       "|Translate English to Shakespearean: every man you meet  |            you do not meet a man but frowns            |\n",
       "|                these days is frowning                  |                                                        |\n",
       "| Translate English to Shakespearean: our bodies are in  | our bloods no more obey the heavens than our courtiers |\n",
       "|  agreement with the planetary influences just as the   |               still seem as does the king              |\n",
       "|      courtierss moods seem to reflect the kings        |                                                        |\n",
       "+-----------------------------------------------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                                    Sample Data                                                    \u001b[0m\n",
       "+-----------------------------------------------------------------------------------------------------------------+\n",
       "|\u001b[1m                      source_text                      \u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                      target_text                      \u001b[0m|\n",
       "|--------------------------------------------------------+--------------------------------------------------------|\n",
       "|Translate English to Shakespearean: every man you meet  |            you do not meet a man but frowns            |\n",
       "|                these days is frowning                  |                                                        |\n",
       "| Translate English to Shakespearean: our bodies are in  | our bloods no more obey the heavens than our courtiers |\n",
       "|  agreement with the planetary influences just as the   |               still seem as does the king              |\n",
       "|      courtierss moods seem to reflect the kings        |                                                        |\n",
       "+-----------------------------------------------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">FULL Dataset: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "FULL Dataset: \u001b[1m(\u001b[0m\u001b[1;36m20000\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">TRAIN Dataset: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19960</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "TRAIN Dataset: \u001b[1m(\u001b[0m\u001b[1;36m19960\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">TEST Dataset: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">40</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "TEST Dataset: \u001b[1m(\u001b[0m\u001b[1;36m40\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"font-weight: bold\">[</span>Initiating Fine Tuning<span style=\"font-weight: bold\">]</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                             <a href=\"file:///var/tmp/ipykernel_294843/2315885737.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2315885737.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///var/tmp/ipykernel_294843/2315885737.py#79\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">79</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mInitiating Fine Tuning\u001b[1m]\u001b[0m\u001b[33m...\u001b[0m                                                             \u001b]8;id=99041;file:///var/tmp/ipykernel_294843/2315885737.py\u001b\\\u001b[2m2315885737.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=431996;file:///var/tmp/ipykernel_294843/2315885737.py#79\u001b\\\u001b[2m79\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m                                                                                        \u001b[2m                \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6500  | tensor(3.5547, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6500  | tensor(3.5547, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6500  | tensor(3.5547, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 7000  | tensor(3.4398, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6500  | tensor(3.5547, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 7000  | tensor(3.4398, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6500  | tensor(3.5547, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 7000  | tensor(3.4398, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 7500  | tensor(3.9838, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6500  | tensor(3.5547, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 7000  | tensor(3.4398, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 7500  | tensor(3.9838, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6500  | tensor(3.5547, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 7000  | tensor(3.4398, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 7500  | tensor(3.9838, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 8000  | tensor(3.0973, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6500  | tensor(3.5547, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 7000  | tensor(3.4398, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 7500  | tensor(3.9838, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 8000  | tensor(3.0973, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6500  | tensor(3.5547, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 7000  | tensor(3.4398, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 7500  | tensor(3.9838, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 8000  | tensor(3.0973, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 8500  | tensor(1.8334, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6500  | tensor(3.5547, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 7000  | tensor(3.4398, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 7500  | tensor(3.9838, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 8000  | tensor(3.0973, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 8500  | tensor(1.8334, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6500  | tensor(3.5547, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 7000  | tensor(3.4398, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 7500  | tensor(3.9838, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 8000  | tensor(3.0973, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 8500  | tensor(1.8334, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 9000  | tensor(2.4744, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6500  | tensor(3.5547, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 7000  | tensor(3.4398, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 7500  | tensor(3.9838, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 8000  | tensor(3.0973, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 8500  | tensor(1.8334, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 9000  | tensor(2.4744, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6500  | tensor(3.5547, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 7000  | tensor(3.4398, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 7500  | tensor(3.9838, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 8000  | tensor(3.0973, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 8500  | tensor(1.8334, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 9000  | tensor(2.4744, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 9500  | tensor(3.2739, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6500  | tensor(3.5547, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 7000  | tensor(3.4398, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 7500  | tensor(3.9838, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 8000  | tensor(3.0973, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 8500  | tensor(1.8334, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 9000  | tensor(2.4744, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 9500  | tensor(3.2739, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[19:42:00] </span><span style=\"font-weight: bold\">[</span>Initiating Validation<span style=\"font-weight: bold\">]</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                              <a href=\"file:///var/tmp/ipykernel_294843/2315885737.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2315885737.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///var/tmp/ipykernel_294843/2315885737.py#83\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">83</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[19:42:00]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mInitiating Validation\u001b[1m]\u001b[0m\u001b[33m...\u001b[0m                                                              \u001b]8;id=927993;file:///var/tmp/ipykernel_294843/2315885737.py\u001b\\\u001b[2m2315885737.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=673785;file:///var/tmp/ipykernel_294843/2315885737.py#83\u001b\\\u001b[2m83\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m                                                                                        \u001b[2m                \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">loss: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.3664</span>, <span style=\"color: #808000; text-decoration-color: #808000\">device</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'cuda:0'</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "loss: \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m3.3664\u001b[0m, \u001b[33mdevice\u001b[0m=\u001b[32m'cuda:0'\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6500  | tensor(3.5547, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 7000  | tensor(3.4398, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 7500  | tensor(3.9838, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 8000  | tensor(3.0973, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 8500  | tensor(1.8334, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 9000  | tensor(2.4744, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 9500  | tensor(3.2739, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(4.3466, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6500  | tensor(3.5547, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 7000  | tensor(3.4398, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 7500  | tensor(3.9838, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 8000  | tensor(3.0973, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 8500  | tensor(1.8334, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 9000  | tensor(2.4744, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 9500  | tensor(3.2739, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(4.3466, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6500  | tensor(3.5547, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 7000  | tensor(3.4398, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 7500  | tensor(3.9838, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 8000  | tensor(3.0973, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 8500  | tensor(1.8334, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 9000  | tensor(2.4744, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 9500  | tensor(3.2739, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(4.3466, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  500  | tensor(1.8999, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6500  | tensor(3.5547, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 7000  | tensor(3.4398, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 7500  | tensor(3.9838, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 8000  | tensor(3.0973, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 8500  | tensor(1.8334, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 9000  | tensor(2.4744, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 9500  | tensor(3.2739, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(4.3466, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  500  | tensor(1.8999, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6500  | tensor(3.5547, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 7000  | tensor(3.4398, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 7500  | tensor(3.9838, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 8000  | tensor(3.0973, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 8500  | tensor(1.8334, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 9000  | tensor(2.4744, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 9500  | tensor(3.2739, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(4.3466, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  500  | tensor(1.8999, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(1.4629, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6500  | tensor(3.5547, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 7000  | tensor(3.4398, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 7500  | tensor(3.9838, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 8000  | tensor(3.0973, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 8500  | tensor(1.8334, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 9000  | tensor(2.4744, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 9500  | tensor(3.2739, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(4.3466, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  500  | tensor(1.8999, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(1.4629, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6500  | tensor(3.5547, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 7000  | tensor(3.4398, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 7500  | tensor(3.9838, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 8000  | tensor(3.0973, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 8500  | tensor(1.8334, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 9000  | tensor(2.4744, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 9500  | tensor(3.2739, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(4.3466, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  500  | tensor(1.8999, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(1.4629, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1500  | tensor(2.2721, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6500  | tensor(3.5547, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 7000  | tensor(3.4398, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 7500  | tensor(3.9838, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 8000  | tensor(3.0973, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 8500  | tensor(1.8334, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 9000  | tensor(2.4744, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 9500  | tensor(3.2739, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(4.3466, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  500  | tensor(1.8999, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(1.4629, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1500  | tensor(2.2721, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6500  | tensor(3.5547, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 7000  | tensor(3.4398, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 7500  | tensor(3.9838, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 8000  | tensor(3.0973, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 8500  | tensor(1.8334, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 9000  | tensor(2.4744, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 9500  | tensor(3.2739, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(4.3466, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  500  | tensor(1.8999, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(1.4629, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1500  | tensor(2.2721, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 2000  | tensor(2.5485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6500  | tensor(3.5547, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 7000  | tensor(3.4398, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 7500  | tensor(3.9838, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 8000  | tensor(3.0973, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 8500  | tensor(1.8334, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 9000  | tensor(2.4744, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 9500  | tensor(3.2739, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(4.3466, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  500  | tensor(1.8999, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(1.4629, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1500  | tensor(2.2721, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 2000  | tensor(2.5485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6500  | tensor(3.5547, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 7000  | tensor(3.4398, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 7500  | tensor(3.9838, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 8000  | tensor(3.0973, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 8500  | tensor(1.8334, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 9000  | tensor(2.4744, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 9500  | tensor(3.2739, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(4.3466, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  500  | tensor(1.8999, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(1.4629, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1500  | tensor(2.2721, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 2000  | tensor(2.5485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 2500  | tensor(2.0093, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6500  | tensor(3.5547, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 7000  | tensor(3.4398, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 7500  | tensor(3.9838, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 8000  | tensor(3.0973, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 8500  | tensor(1.8334, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 9000  | tensor(2.4744, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 9500  | tensor(3.2739, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(4.3466, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  500  | tensor(1.8999, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(1.4629, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1500  | tensor(2.2721, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 2000  | tensor(2.5485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 2500  | tensor(2.0093, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6500  | tensor(3.5547, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 7000  | tensor(3.4398, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 7500  | tensor(3.9838, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 8000  | tensor(3.0973, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 8500  | tensor(1.8334, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 9000  | tensor(2.4744, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 9500  | tensor(3.2739, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(4.3466, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  500  | tensor(1.8999, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(1.4629, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1500  | tensor(2.2721, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 2000  | tensor(2.5485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 2500  | tensor(2.0093, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 3000  | tensor(1.2859, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6500  | tensor(3.5547, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 7000  | tensor(3.4398, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 7500  | tensor(3.9838, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 8000  | tensor(3.0973, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 8500  | tensor(1.8334, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 9000  | tensor(2.4744, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 9500  | tensor(3.2739, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(4.3466, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  500  | tensor(1.8999, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(1.4629, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1500  | tensor(2.2721, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 2000  | tensor(2.5485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 2500  | tensor(2.0093, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 3000  | tensor(1.2859, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6500  | tensor(3.5547, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 7000  | tensor(3.4398, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 7500  | tensor(3.9838, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 8000  | tensor(3.0973, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 8500  | tensor(1.8334, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 9000  | tensor(2.4744, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 9500  | tensor(3.2739, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(4.3466, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  500  | tensor(1.8999, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(1.4629, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1500  | tensor(2.2721, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 2000  | tensor(2.5485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 2500  | tensor(2.0093, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 3000  | tensor(1.2859, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 3500  | tensor(4.0834, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6500  | tensor(3.5547, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 7000  | tensor(3.4398, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 7500  | tensor(3.9838, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 8000  | tensor(3.0973, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 8500  | tensor(1.8334, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 9000  | tensor(2.4744, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 9500  | tensor(3.2739, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(4.3466, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  500  | tensor(1.8999, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(1.4629, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1500  | tensor(2.2721, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 2000  | tensor(2.5485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 2500  | tensor(2.0093, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 3000  | tensor(1.2859, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 3500  | tensor(4.0834, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6500  | tensor(3.5547, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 7000  | tensor(3.4398, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 7500  | tensor(3.9838, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 8000  | tensor(3.0973, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 8500  | tensor(1.8334, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 9000  | tensor(2.4744, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 9500  | tensor(3.2739, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(4.3466, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  500  | tensor(1.8999, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(1.4629, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1500  | tensor(2.2721, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 2000  | tensor(2.5485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 2500  | tensor(2.0093, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 3000  | tensor(1.2859, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 3500  | tensor(4.0834, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 4000  | tensor(2.1942, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6500  | tensor(3.5547, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 7000  | tensor(3.4398, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 7500  | tensor(3.9838, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 8000  | tensor(3.0973, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 8500  | tensor(1.8334, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 9000  | tensor(2.4744, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 9500  | tensor(3.2739, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(4.3466, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  500  | tensor(1.8999, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(1.4629, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1500  | tensor(2.2721, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 2000  | tensor(2.5485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 2500  | tensor(2.0093, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 3000  | tensor(1.2859, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 3500  | tensor(4.0834, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 4000  | tensor(2.1942, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6500  | tensor(3.5547, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 7000  | tensor(3.4398, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 7500  | tensor(3.9838, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 8000  | tensor(3.0973, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 8500  | tensor(1.8334, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 9000  | tensor(2.4744, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 9500  | tensor(3.2739, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(4.3466, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  500  | tensor(1.8999, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(1.4629, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1500  | tensor(2.2721, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 2000  | tensor(2.5485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 2500  | tensor(2.0093, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 3000  | tensor(1.2859, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 3500  | tensor(4.0834, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 4000  | tensor(2.1942, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 4500  | tensor(3.3372, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6500  | tensor(3.5547, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 7000  | tensor(3.4398, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 7500  | tensor(3.9838, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 8000  | tensor(3.0973, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 8500  | tensor(1.8334, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 9000  | tensor(2.4744, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 9500  | tensor(3.2739, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(4.3466, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  500  | tensor(1.8999, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(1.4629, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1500  | tensor(2.2721, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 2000  | tensor(2.5485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 2500  | tensor(2.0093, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 3000  | tensor(1.2859, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 3500  | tensor(4.0834, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 4000  | tensor(2.1942, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 4500  | tensor(3.3372, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6500  | tensor(3.5547, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 7000  | tensor(3.4398, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 7500  | tensor(3.9838, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 8000  | tensor(3.0973, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 8500  | tensor(1.8334, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 9000  | tensor(2.4744, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 9500  | tensor(3.2739, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(4.3466, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  500  | tensor(1.8999, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(1.4629, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1500  | tensor(2.2721, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 2000  | tensor(2.5485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 2500  | tensor(2.0093, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 3000  | tensor(1.2859, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 3500  | tensor(4.0834, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 4000  | tensor(2.1942, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 4500  | tensor(3.3372, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 5000  | tensor(4.4174, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6500  | tensor(3.5547, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 7000  | tensor(3.4398, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 7500  | tensor(3.9838, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 8000  | tensor(3.0973, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 8500  | tensor(1.8334, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 9000  | tensor(2.4744, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 9500  | tensor(3.2739, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(4.3466, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  500  | tensor(1.8999, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(1.4629, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1500  | tensor(2.2721, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 2000  | tensor(2.5485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 2500  | tensor(2.0093, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 3000  | tensor(1.2859, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 3500  | tensor(4.0834, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 4000  | tensor(2.1942, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 4500  | tensor(3.3372, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 5000  | tensor(4.4174, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6500  | tensor(3.5547, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 7000  | tensor(3.4398, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 7500  | tensor(3.9838, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 8000  | tensor(3.0973, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 8500  | tensor(1.8334, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 9000  | tensor(2.4744, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 9500  | tensor(3.2739, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(4.3466, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  500  | tensor(1.8999, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(1.4629, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1500  | tensor(2.2721, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 2000  | tensor(2.5485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 2500  | tensor(2.0093, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 3000  | tensor(1.2859, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 3500  | tensor(4.0834, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 4000  | tensor(2.1942, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 4500  | tensor(3.3372, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 5000  | tensor(4.4174, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 5500  | tensor(3.6426, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6500  | tensor(3.5547, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 7000  | tensor(3.4398, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 7500  | tensor(3.9838, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 8000  | tensor(3.0973, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 8500  | tensor(1.8334, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 9000  | tensor(2.4744, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 9500  | tensor(3.2739, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(4.3466, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  500  | tensor(1.8999, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(1.4629, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1500  | tensor(2.2721, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 2000  | tensor(2.5485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 2500  | tensor(2.0093, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 3000  | tensor(1.2859, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 3500  | tensor(4.0834, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 4000  | tensor(2.1942, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 4500  | tensor(3.3372, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 5000  | tensor(4.4174, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 5500  | tensor(3.6426, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6500  | tensor(3.5547, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 7000  | tensor(3.4398, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 7500  | tensor(3.9838, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 8000  | tensor(3.0973, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 8500  | tensor(1.8334, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 9000  | tensor(2.4744, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 9500  | tensor(3.2739, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(4.3466, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  500  | tensor(1.8999, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(1.4629, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1500  | tensor(2.2721, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 2000  | tensor(2.5485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 2500  | tensor(2.0093, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 3000  | tensor(1.2859, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 3500  | tensor(4.0834, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 4000  | tensor(2.1942, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 4500  | tensor(3.3372, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 5000  | tensor(4.4174, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 5500  | tensor(3.6426, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 6000  | tensor(3.1389, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6500  | tensor(3.5547, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 7000  | tensor(3.4398, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 7500  | tensor(3.9838, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 8000  | tensor(3.0973, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 8500  | tensor(1.8334, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 9000  | tensor(2.4744, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 9500  | tensor(3.2739, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(4.3466, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  500  | tensor(1.8999, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(1.4629, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1500  | tensor(2.2721, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 2000  | tensor(2.5485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 2500  | tensor(2.0093, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 3000  | tensor(1.2859, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 3500  | tensor(4.0834, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 4000  | tensor(2.1942, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 4500  | tensor(3.3372, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 5000  | tensor(4.4174, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 5500  | tensor(3.6426, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 6000  | tensor(3.1389, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6500  | tensor(3.5547, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 7000  | tensor(3.4398, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 7500  | tensor(3.9838, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 8000  | tensor(3.0973, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 8500  | tensor(1.8334, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 9000  | tensor(2.4744, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 9500  | tensor(3.2739, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(4.3466, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  500  | tensor(1.8999, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(1.4629, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1500  | tensor(2.2721, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 2000  | tensor(2.5485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 2500  | tensor(2.0093, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 3000  | tensor(1.2859, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 3500  | tensor(4.0834, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 4000  | tensor(2.1942, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 4500  | tensor(3.3372, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 5000  | tensor(4.4174, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 5500  | tensor(3.6426, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 6000  | tensor(3.1389, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 6500  | tensor(4.5780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6500  | tensor(3.5547, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 7000  | tensor(3.4398, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 7500  | tensor(3.9838, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 8000  | tensor(3.0973, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 8500  | tensor(1.8334, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 9000  | tensor(2.4744, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 9500  | tensor(3.2739, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(4.3466, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  500  | tensor(1.8999, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(1.4629, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1500  | tensor(2.2721, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 2000  | tensor(2.5485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 2500  | tensor(2.0093, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 3000  | tensor(1.2859, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 3500  | tensor(4.0834, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 4000  | tensor(2.1942, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 4500  | tensor(3.3372, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 5000  | tensor(4.4174, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 5500  | tensor(3.6426, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 6000  | tensor(3.1389, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 6500  | tensor(4.5780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6500  | tensor(3.5547, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 7000  | tensor(3.4398, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 7500  | tensor(3.9838, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 8000  | tensor(3.0973, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 8500  | tensor(1.8334, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 9000  | tensor(2.4744, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 9500  | tensor(3.2739, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(4.3466, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  500  | tensor(1.8999, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(1.4629, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1500  | tensor(2.2721, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 2000  | tensor(2.5485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 2500  | tensor(2.0093, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 3000  | tensor(1.2859, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 3500  | tensor(4.0834, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 4000  | tensor(2.1942, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 4500  | tensor(3.3372, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 5000  | tensor(4.4174, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 5500  | tensor(3.6426, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 6000  | tensor(3.1389, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 6500  | tensor(4.5780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 7000  | tensor(1.3882, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6500  | tensor(3.5547, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 7000  | tensor(3.4398, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 7500  | tensor(3.9838, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 8000  | tensor(3.0973, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 8500  | tensor(1.8334, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 9000  | tensor(2.4744, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 9500  | tensor(3.2739, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(4.3466, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  500  | tensor(1.8999, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(1.4629, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1500  | tensor(2.2721, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 2000  | tensor(2.5485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 2500  | tensor(2.0093, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 3000  | tensor(1.2859, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 3500  | tensor(4.0834, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 4000  | tensor(2.1942, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 4500  | tensor(3.3372, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 5000  | tensor(4.4174, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 5500  | tensor(3.6426, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 6000  | tensor(3.1389, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 6500  | tensor(4.5780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 7000  | tensor(1.3882, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6500  | tensor(3.5547, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 7000  | tensor(3.4398, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 7500  | tensor(3.9838, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 8000  | tensor(3.0973, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 8500  | tensor(1.8334, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 9000  | tensor(2.4744, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 9500  | tensor(3.2739, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(4.3466, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  500  | tensor(1.8999, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(1.4629, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1500  | tensor(2.2721, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 2000  | tensor(2.5485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 2500  | tensor(2.0093, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 3000  | tensor(1.2859, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 3500  | tensor(4.0834, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 4000  | tensor(2.1942, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 4500  | tensor(3.3372, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 5000  | tensor(4.4174, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 5500  | tensor(3.6426, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 6000  | tensor(3.1389, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 6500  | tensor(4.5780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 7000  | tensor(1.3882, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 7500  | tensor(3.1831, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6500  | tensor(3.5547, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 7000  | tensor(3.4398, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 7500  | tensor(3.9838, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 8000  | tensor(3.0973, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 8500  | tensor(1.8334, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 9000  | tensor(2.4744, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 9500  | tensor(3.2739, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(4.3466, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  500  | tensor(1.8999, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(1.4629, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1500  | tensor(2.2721, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 2000  | tensor(2.5485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 2500  | tensor(2.0093, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 3000  | tensor(1.2859, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 3500  | tensor(4.0834, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 4000  | tensor(2.1942, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 4500  | tensor(3.3372, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 5000  | tensor(4.4174, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 5500  | tensor(3.6426, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 6000  | tensor(3.1389, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 6500  | tensor(4.5780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 7000  | tensor(1.3882, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 7500  | tensor(3.1831, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6500  | tensor(3.5547, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 7000  | tensor(3.4398, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 7500  | tensor(3.9838, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 8000  | tensor(3.0973, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 8500  | tensor(1.8334, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 9000  | tensor(2.4744, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 9500  | tensor(3.2739, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(4.3466, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  500  | tensor(1.8999, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(1.4629, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1500  | tensor(2.2721, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 2000  | tensor(2.5485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 2500  | tensor(2.0093, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 3000  | tensor(1.2859, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 3500  | tensor(4.0834, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 4000  | tensor(2.1942, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 4500  | tensor(3.3372, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 5000  | tensor(4.4174, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 5500  | tensor(3.6426, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 6000  | tensor(3.1389, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 6500  | tensor(4.5780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 7000  | tensor(1.3882, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 7500  | tensor(3.1831, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 8000  | tensor(2.6786, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6500  | tensor(3.5547, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 7000  | tensor(3.4398, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 7500  | tensor(3.9838, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 8000  | tensor(3.0973, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 8500  | tensor(1.8334, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 9000  | tensor(2.4744, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 9500  | tensor(3.2739, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(4.3466, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  500  | tensor(1.8999, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(1.4629, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1500  | tensor(2.2721, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 2000  | tensor(2.5485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 2500  | tensor(2.0093, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 3000  | tensor(1.2859, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 3500  | tensor(4.0834, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 4000  | tensor(2.1942, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 4500  | tensor(3.3372, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 5000  | tensor(4.4174, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 5500  | tensor(3.6426, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 6000  | tensor(3.1389, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 6500  | tensor(4.5780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 7000  | tensor(1.3882, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 7500  | tensor(3.1831, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 8000  | tensor(2.6786, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6500  | tensor(3.5547, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 7000  | tensor(3.4398, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 7500  | tensor(3.9838, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 8000  | tensor(3.0973, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 8500  | tensor(1.8334, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 9000  | tensor(2.4744, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 9500  | tensor(3.2739, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(4.3466, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  500  | tensor(1.8999, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(1.4629, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1500  | tensor(2.2721, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 2000  | tensor(2.5485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 2500  | tensor(2.0093, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 3000  | tensor(1.2859, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 3500  | tensor(4.0834, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 4000  | tensor(2.1942, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 4500  | tensor(3.3372, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 5000  | tensor(4.4174, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 5500  | tensor(3.6426, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 6000  | tensor(3.1389, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 6500  | tensor(4.5780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 7000  | tensor(1.3882, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 7500  | tensor(3.1831, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 8000  | tensor(2.6786, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 8500  | tensor(1.7214, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6500  | tensor(3.5547, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 7000  | tensor(3.4398, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 7500  | tensor(3.9838, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 8000  | tensor(3.0973, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 8500  | tensor(1.8334, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 9000  | tensor(2.4744, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 9500  | tensor(3.2739, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(4.3466, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  500  | tensor(1.8999, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(1.4629, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1500  | tensor(2.2721, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 2000  | tensor(2.5485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 2500  | tensor(2.0093, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 3000  | tensor(1.2859, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 3500  | tensor(4.0834, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 4000  | tensor(2.1942, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 4500  | tensor(3.3372, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 5000  | tensor(4.4174, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 5500  | tensor(3.6426, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 6000  | tensor(3.1389, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 6500  | tensor(4.5780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 7000  | tensor(1.3882, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 7500  | tensor(3.1831, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 8000  | tensor(2.6786, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 8500  | tensor(1.7214, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 6500  | tensor(3.5547, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 7000  | tensor(3.4398, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 7500  | tensor(3.9838, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 8000  | tensor(3.0973, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 8500  | tensor(1.8334, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 9000  | tensor(2.4744, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   | 9500  | tensor(3.2739, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(4.3466, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  500  | tensor(1.8999, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1000  | tensor(1.4629, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 1500  | tensor(2.2721, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 2000  | tensor(2.5485, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 2500  | tensor(2.0093, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 3000  | tensor(1.2859, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 3500  | tensor(4.0834, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 4000  | tensor(2.1942, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 4500  | tensor(3.3372, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 5000  | tensor(4.4174, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 5500  | tensor(3.6426, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 6000  | tensor(3.1389, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 6500  | tensor(4.5780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 7000  | tensor(1.3882, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 7500  | tensor(3.1831, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 8000  | tensor(2.6786, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 8500  | tensor(1.7214, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   | 9000  | tensor(3.6410, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(9.9361, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  500  | tensor(3.7519, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1000  | tensor(1.4152, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 1500  | tensor(3.2544, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2000  | tensor(4.8772, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 2500  | tensor(3.4691, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3000  | tensor(3.1583, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 3500  | tensor(2.8779, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4000  | tensor(3.4171, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 4500  | tensor(3.0024, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5000  | tensor(3.5004, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 5500  | tensor(4.0300, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6000  | tensor(2.0338, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 6500  | tensor(3.5547, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 7000  | tensor(3.4398, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 7500  | tensor(3.9838, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 8000  | tensor(3.0973, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 8500  | tensor(1.8334, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 9000  | tensor(2.4744, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   | 9500  | tensor(3.2739, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(4.3466, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  500  | tensor(1.8999, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1000  | tensor(1.4629, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 1500  | tensor(2.2721, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 2000  | tensor(2.5485, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 2500  | tensor(2.0093, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 3000  | tensor(1.2859, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 3500  | tensor(4.0834, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 4000  | tensor(2.1942, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 4500  | tensor(3.3372, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 5000  | tensor(4.4174, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 5500  | tensor(3.6426, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 6000  | tensor(3.1389, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 6500  | tensor(4.5780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 7000  | tensor(1.3882, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 7500  | tensor(3.1831, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 8000  | tensor(2.6786, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 8500  | tensor(1.7214, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   | 9000  | tensor(3.6410, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BartTrainer(\n",
    "    dataframe=df,\n",
    "    source_text=\"title\",\n",
    "    target_text=\"keywords\",\n",
    "    model_params=model_params,\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    output_dir = output_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c47ae0-cd8e-438a-96be-1aa6caeb7a0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e69495-2cf9-4e52-b481-ee4dc4c4e8e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
